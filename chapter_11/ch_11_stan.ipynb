{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pystan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "az.style.use('arviz-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>deaths</th>\n",
       "      <th>category</th>\n",
       "      <th>min_pressure</th>\n",
       "      <th>damage_norm</th>\n",
       "      <th>female</th>\n",
       "      <th>femininity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Gustav</td>\n",
       "      <td>2008</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>954</td>\n",
       "      <td>4360</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.567471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Ike</td>\n",
       "      <td>2008</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>950</td>\n",
       "      <td>20370</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.515826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Irene</td>\n",
       "      <td>2011</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>952</td>\n",
       "      <td>7110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.773725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Isaac</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>966</td>\n",
       "      <td>24000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.498613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Sandy</td>\n",
       "      <td>2012</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>942</td>\n",
       "      <td>75000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  year  deaths  category  min_pressure  damage_norm  female  \\\n",
       "87  Gustav  2008      52         2           954         4360       0   \n",
       "88     Ike  2008      84         2           950        20370       0   \n",
       "89   Irene  2011      41         1           952         7110       1   \n",
       "90   Isaac  2012       5         1           966        24000       0   \n",
       "91   Sandy  2012     159         2           942        75000       1   \n",
       "\n",
       "    femininity  \n",
       "87   -1.567471  \n",
       "88   -1.515826  \n",
       "89    0.773725  \n",
       "90   -1.498613  \n",
       "91    0.687651  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## From Pymc3 devs notebook:\n",
    "def stdz(series: pd.Series):\n",
    "    \"\"\"Standardize the given pandas Series\"\"\"\n",
    "    return (series - series.mean())/series.std()\n",
    "\n",
    "hurricanes = pd.read_csv(\"/Users/benjaminwee/Documents/courses/resources/Rethinking/Data/hurricanes.csv\", sep=\";\")\n",
    "\n",
    "# Standardize predictor, as usual\n",
    "hurricanes[\"femininity\"] = stdz(hurricanes.femininity)\n",
    "hurricanes.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_11_h1 = '''\n",
    "data {\n",
    "  int N;\n",
    "  real fem[N];\n",
    "  int deaths[N];\n",
    "}\n",
    "parameters {\n",
    "  real a;\n",
    "  real b;\n",
    "}\n",
    "model {\n",
    "  vector[N] lambda;\n",
    "  target += normal_lpdf(a | 0, 4.5);\n",
    "  target += normal_lpdf(b | 0, 0.8);\n",
    "  \n",
    "  for(n in 1:N) lambda[n] = a + b * fem[n];\n",
    "    target += poisson_log_lpmf(deaths | lambda);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_9b8d736d7fdd96f9749c582152ee30c5 NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_h11_1 = pystan.StanModel(model_code=m_11_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h11_1 = dict(N=len(hurricanes),\n",
    "                fem = hurricanes['femininity'],\n",
    "                deaths = hurricanes['deaths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_h11_1 = sm_h11_1.sampling(data=df_h11_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_9b8d736d7fdd96f9749c582152ee30c5.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "a       3.0  4.4e-4   0.02   2.95   2.99    3.0   3.02   3.05   2893    1.0\n",
       "b      0.24  4.8e-4   0.03   0.19   0.22   0.24   0.26   0.29   2802    1.0\n",
       "lp__  -2135    0.02   1.01  -2138  -2136  -2135  -2134  -2134   1887    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Mon May 25 22:52:52 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_h11_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_11_h1_2 = '''\n",
    "data {\n",
    "  int N;\n",
    "  int deaths[N];\n",
    "}\n",
    "parameters {\n",
    "  real a;\n",
    "}\n",
    "model {\n",
    "  vector[N] lambda;\n",
    "  target += normal_lpdf(a | 0, 4.5);\n",
    "  \n",
    "  for(n in 1:N) lambda[n] = a;\n",
    "    target += poisson_log_lpmf(deaths | lambda);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_b9cb89b5ffd8dfc50fa173f2ef609558 NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_h11_2 = pystan.StanModel(model_code=m_11_h1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h11_2 = dict(N=len(hurricanes),\n",
    "                deaths = hurricanes['deaths'])\n",
    "\n",
    "fit_h11_2 = sm_h11_2.sampling(data=df_h11_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_b9cb89b5ffd8dfc50fa173f2ef609558.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "a      3.03  5.7e-4   0.02   2.98   3.01   3.03   3.04   3.07   1614    1.0\n",
       "lp__  -2181    0.02    0.7  -2183  -2181  -2181  -2181  -2181   1682    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Mon May 25 22:55:37 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_h11_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_11_h2 = '''\n",
    "data {\n",
    "  int N;\n",
    "  real fem[N];\n",
    "  int deaths[N];\n",
    "}\n",
    "parameters {\n",
    "  real a;\n",
    "  real b;\n",
    "  real phi;\n",
    "}\n",
    "model {\n",
    "  vector[N] lambda;\n",
    "  target += normal_lpdf(a | 0, 4.5);\n",
    "  target += normal_lpdf(b | 0, 0.8);\n",
    "  target += exponential_lpdf(phi | 1);\n",
    "  \n",
    "  for(n in 1:N) lambda[n] = a + b * fem[n];\n",
    "    target += neg_binomial_2_lpmf(deaths | lambda, phi);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1d8a9bd5a6209aa2e7f7b2ebc134060b NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_h11_h2 = pystan.StanModel(model_code=m_11_h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_1d8a9bd5a6209aa2e7f7b2ebc134060b.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "a     15.97    0.03   1.86  12.55  14.66  15.89  17.21  19.89   3361    1.0\n",
       "b      0.37    0.01   0.77  -1.14  -0.15   0.38   0.89   1.86   3221    1.0\n",
       "phi    0.44  1.1e-3   0.06   0.33    0.4   0.44   0.48   0.57   2961    1.0\n",
       "lp__ -364.9    0.03   1.23 -368.1 -365.5 -364.6 -364.0 -363.5   1955    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Mon May 25 23:00:30 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h11_h2 = dict(N=len(hurricanes),\n",
    "                fem = hurricanes['femininity'],\n",
    "                deaths = hurricanes['deaths'])\n",
    "\n",
    "fit_h11_h2 = sm_h11_h2.sampling(data=df_h11_h2)\n",
    "\n",
    "fit_h11_h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11H3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"femininity\", \"min_pressure\", \"damage_norm\"]:\n",
    "    hurricanes[f\"{col}_std\"] = stdz(hurricanes[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurricanes['inter'] = hurricanes['femininity_std'] * hurricanes['min_pressure_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_11_h3_1 = '''\n",
    "data {\n",
    "  int N;\n",
    "  int deaths[N];\n",
    "  real fem[N];\n",
    "  real min_pressure_std[N];\n",
    "  real inter[N];\n",
    "}\n",
    "parameters {\n",
    "  real a;\n",
    "  real bf;\n",
    "  real bp;\n",
    "  real bfp;\n",
    "}\n",
    "model {\n",
    "  vector[N] lambda;\n",
    "  target += normal_lpdf(a | 0, 4.5);\n",
    "  target += normal_lpdf(bf | 0, 0.8);\n",
    "  target += normal_lpdf(bp| 0, 0.8);\n",
    "  target += normal_lpdf(bfp | 0, 0.8);\n",
    "    \n",
    "  for(n in 1:N) lambda[n] = a + bf*fem[N]+bp*min_pressure_std[N]+bfp*inter[N];\n",
    "    target += poisson_log_lpmf(deaths | lambda);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_481729241d3a7e471dd23d86dfb4a56d NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_h11_h3_1 = pystan.StanModel(model_code=m_11_h3_1)\n",
    "df_h11_h3_1 = dict(N=len(hurricanes),\n",
    "                fem = hurricanes['femininity_std'],\n",
    "                deaths = hurricanes['deaths'],\n",
    "                inter = hurricanes['inter'],\n",
    "                min_pressure_std = hurricanes['min_pressure_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_481729241d3a7e471dd23d86dfb4a56d.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "a      2.74    0.03   1.21   0.33   1.93   2.75   3.53   5.14   1831    1.0\n",
       "bf     0.08    0.02   0.79  -1.42  -0.45   0.07    0.6   1.66   2227    1.0\n",
       "bp    -0.14    0.02   0.76  -1.62  -0.65  -0.13   0.36   1.34   2136    1.0\n",
       "bfp   -0.08    0.02   0.81   -1.7  -0.63  -0.09   0.47   1.54   2278    1.0\n",
       "lp__  -2185    0.04   1.39  -2188  -2185  -2184  -2184  -2183   1404    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Mon May 25 23:43:10 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_h11_h3_1 = sm_h11_h3_1.sampling(data=df_h11_h3_1)\n",
    "\n",
    "fit_h11_h3_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_11_h3_2 = '''\n",
    "data {\n",
    "  int N;\n",
    "  int deaths[N];\n",
    "  real fem[N];\n",
    "  real min_pressure_std[N];\n",
    "}\n",
    "parameters {\n",
    "  real a;\n",
    "  real bf;\n",
    "  real bp;\n",
    "}\n",
    "model {\n",
    "  vector[N] lambda;\n",
    "  target += normal_lpdf(a | 0, 4.5);\n",
    "  target += normal_lpdf(bf | 0, 0.8);\n",
    "  target += normal_lpdf(bp| 0, 0.8);\n",
    "    \n",
    "  for(n in 1:N) lambda[n] = a + bf*fem[N]+bp*min_pressure_std[N];\n",
    "    target += poisson_log_lpmf(deaths | lambda);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_11_h3_2 = pystan.StanModel(model_code=m_11_h3_2)\n",
    "df_h11_h3_2 = dict(N=len(hurricanes),\n",
    "                fem = hurricanes['femininity_std'],\n",
    "                deaths = hurricanes['deaths'],\n",
    "                min_pressure_std = hurricanes['min_pressure_std'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_h11_h3_2 = sm_11_h3_2.sampling(data=df_h11_h3_2)\n",
    "\n",
    "fit_h11_h3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_11_h3_3 = '''\n",
    "data {\n",
    "  int N;\n",
    "  int deaths[N];\n",
    "  real fem[N];\n",
    "  real damage_std[N];\n",
    "  real inter_damage[N];\n",
    "}\n",
    "parameters {\n",
    "  real a;\n",
    "  real bf;\n",
    "  real bd;\n",
    "  real bfd;\n",
    "}\n",
    "model {\n",
    "  vector[N] lambda;\n",
    "  target += normal_lpdf(a | 0, 4.5);\n",
    "  target += normal_lpdf(bf | 0, 0.8);\n",
    "  target += normal_lpdf(bd| 0, 0.8);\n",
    "  target += normal_lpdf(bfd | 0, 0.8);\n",
    "    \n",
    "  for(n in 1:N) lambda[n] = a + bf*fem[N]+bd*damage_std[N]+bfd*inter_damage[N];\n",
    "    target += poisson_log_lpmf(deaths | lambda);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_2d8e22ab7fdc9a378bed52ba460e491a NOW.\n"
     ]
    }
   ],
   "source": [
    "hurricanes['inter_damage'] = hurricanes['femininity_std'] * hurricanes['damage_norm_std']\n",
    "sm_11_h3_3 = pystan.StanModel(model_code=m_11_h3_3)\n",
    "\n",
    "df_h11_h3_3 = dict(N=len(hurricanes),\n",
    "                fem = hurricanes['femininity_std'],\n",
    "                deaths = hurricanes['deaths'],\n",
    "                damage_std = hurricanes['damage_norm_std'],\n",
    "                inter_damage = hurricanes['inter_damage'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:1696 of 4000 iterations saturated the maximum tree depth of 10 (42.4 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_2d8e22ab7fdc9a378bed52ba460e491a.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "a      1.32    0.08   3.43  -5.71  -0.97   1.22    3.7   7.96   2048    1.0\n",
       "bf     0.03    0.02   0.81  -1.59  -0.52   0.03   0.56   1.65   2663    1.0\n",
       "bd     0.21    0.01   0.62  -1.03   -0.2   0.21   0.65   1.37   2046    1.0\n",
       "bfd    0.16    0.01    0.7  -1.21  -0.31   0.16   0.65   1.51   2345    1.0\n",
       "lp__  -2185    0.04   1.36  -2188  -2185  -2184  -2184  -2183   1270    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Mon May 25 23:26:20 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_h11_h3_3 = sm_11_h3_3.sampling(data=df_h11_h3_3)\n",
    "\n",
    "fit_h11_h3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_11_h3_4 = '''\n",
    "data {\n",
    "  int N;\n",
    "  int deaths[N];\n",
    "  real fem[N];\n",
    "  real damage_std[N];\n",
    "  real inter_damage[N];\n",
    "}\n",
    "parameters {\n",
    "  real a;\n",
    "  real bf;\n",
    "  real bd;\n",
    "  real bfd;\n",
    "  real phi;\n",
    "}\n",
    "model {\n",
    "  vector[N] lambda;\n",
    "  target += normal_lpdf(a | 0, 4.5);\n",
    "  target += normal_lpdf(bf | 0, 0.8);\n",
    "  target += normal_lpdf(bd| 0, 0.8);\n",
    "  target += normal_lpdf(bfd | 0, 0.8);\n",
    "  target += exponential_lpdf(phi | 1);\n",
    "    \n",
    "  for(n in 1:N) lambda[n] = a + bf*fem[N]+bd*damage_std[N]+bfd*inter_damage[N];\n",
    "    target += neg_binomial_2_lpmf(deaths | lambda, phi);\n",
    "}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_a9698d5beede2c677c71616af9286b6b NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_11_h3_4 = pystan.StanModel(model_code=m_11_h3_4)\n",
    "\n",
    "df_h11_h3_4 = dict(N=len(hurricanes),\n",
    "                fem = hurricanes['femininity_std'],\n",
    "                deaths = hurricanes['deaths'],\n",
    "                damage_std = hurricanes['damage_norm_std'],\n",
    "                inter_damage = hurricanes['inter_damage'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:1787 of 4000 iterations saturated the maximum tree depth of 10 (44.7 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_2d8e22ab7fdc9a378bed52ba460e491a.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "a      1.31    0.09   3.46  -5.48  -1.02   1.31   3.59   8.17   1611    1.0\n",
       "bf     0.02    0.02   0.79  -1.49   -0.5   0.02   0.55   1.58   2353    1.0\n",
       "bd     0.24    0.02   0.65  -1.02  -0.19   0.22   0.67   1.51   1562    1.0\n",
       "bfd    0.13    0.02   0.75  -1.37  -0.39   0.15   0.65   1.61   2294    1.0\n",
       "lp__  -2185    0.05    1.5  -2188  -2185  -2184  -2184  -2183   1016    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Mon May 25 23:28:09 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_h11_h3_4 = sm_11_h3_3.sampling(data=df_h11_h3_4)\n",
    "\n",
    "fit_h11_h3_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11H6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fish_caught</th>\n",
       "      <th>livebait</th>\n",
       "      <th>camper</th>\n",
       "      <th>persons</th>\n",
       "      <th>child</th>\n",
       "      <th>hours</th>\n",
       "      <th>log_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.124</td>\n",
       "      <td>3.050410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.732</td>\n",
       "      <td>1.746065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.323</td>\n",
       "      <td>0.279902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548</td>\n",
       "      <td>-0.601480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.695</td>\n",
       "      <td>0.527683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fish_caught  livebait  camper  persons  child   hours  log_hours\n",
       "0            0         0       0        1      0  21.124   3.050410\n",
       "1            0         1       1        1      0   5.732   1.746065\n",
       "2            0         1       0        1      0   1.323   0.279902\n",
       "3            0         1       1        2      1   0.548  -0.601480\n",
       "4            1         1       0        1      0   1.695   0.527683"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish = pd.read_csv(\"/Users/benjaminwee/Documents/courses/resources/Rethinking/Data/fish.csv\", sep=\";\")\n",
    "fish['log_hours'] = np.log(fish['hours'])\n",
    "fish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_11_h6_1 = '''\n",
    "data {\n",
    "  int N;\n",
    "  real log_hours[N];\n",
    "  int fish[N];\n",
    "}\n",
    "parameters {\n",
    "  real ap;\n",
    "  real al;\n",
    "}\n",
    "model {\n",
    "  vector[N] p;\n",
    "  vector[N] lambda;\n",
    "  target += normal_lpdf(ap | 0, 10);\n",
    "  target += normal_lpdf(al | 0, 10);\n",
    "  \n",
    "  for(i in 1:N){\n",
    "    p[i] = inv_logit(ap);\n",
    "    lambda[i] = exp(log_hours[i] + al);\n",
    "    if(fish[i] == 0)\n",
    "      target += log_sum_exp(bernoulli_lpmf(1 | p[i]), \n",
    "                            bernoulli_lpmf(0 | p[i]) + poisson_lpmf(fish[i] | lambda[i]));\n",
    "    else\n",
    "      target += bernoulli_lpmf(0 | p[i]) + poisson_lpmf(fish[i] | lambda[i]);\n",
    "  }\n",
    "}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_dbe90a9b52718a8ad777decfaa1d6a1b NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_11_h6_1 = pystan.StanModel(model_code=m_11_h6_1)\n",
    "\n",
    "df_h11_h6_1 = dict(N=len(fish),\n",
    "                log_hours = fish['log_hours'],\n",
    "                fish = fish['fish_caught'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_dbe90a9b52718a8ad777decfaa1d6a1b.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "ap    -0.75  3.0e-3   0.18  -1.11  -0.87  -0.75  -0.63   -0.4   3654    1.0\n",
       "al    -0.14  5.6e-4   0.04  -0.21  -0.17  -0.15  -0.12  -0.07   3934    1.0\n",
       "lp__  -1264    0.02   0.96  -1267  -1264  -1264  -1263  -1263   1827    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Mon May 25 23:37:53 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_h11_h6_1 = sm_11_h6_1.sampling(data=df_h11_h6_1)\n",
    "\n",
    "fit_h11_h6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_11_h6_2 = '''\n",
    "data {\n",
    "  int N;\n",
    "  real log_hours[N];\n",
    "  int fish[N];\n",
    "  int persons[N];\n",
    "  int child[N];\n",
    "}\n",
    "parameters {\n",
    "  real ap;\n",
    "  real al;\n",
    "  real bp0;\n",
    "  real bc0;\n",
    "  real bp;\n",
    "  real bc;\n",
    "}\n",
    "model {\n",
    "  vector[N] p;\n",
    "  vector[N] lambda;\n",
    "  target += normal_lpdf(ap | 0, 10);\n",
    "  target += normal_lpdf(al | 0, 10);\n",
    "  target += normal_lpdf(bp0 | 0, 1);\n",
    "  target += normal_lpdf(bc0 | 0, 1);\n",
    "  target += normal_lpdf(bp| 0, 1);\n",
    "  target += normal_lpdf(bc | 0, 1);\n",
    "  \n",
    "  for(i in 1:N){\n",
    "    p[i] = inv_logit(ap + bp0*persons[i] + bc0*child[i]);\n",
    "    lambda[i] = exp(log_hours[i] + al + bp*persons[i] + bc*child[i]);\n",
    "    if(fish[i] == 0)\n",
    "      target += log_sum_exp(bernoulli_lpmf(1 | p[i]), \n",
    "                            bernoulli_lpmf(0 | p[i]) + poisson_lpmf(fish[i] | lambda[i]));\n",
    "    else\n",
    "      target += bernoulli_lpmf(0 | p[i]) + poisson_lpmf(fish[i] | lambda[i]);\n",
    "  }\n",
    "}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_c32a3ce4c02e39ec64c11fedc2fb2436 NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_11_h6_2 = pystan.StanModel(model_code=m_11_h6_2)\n",
    "\n",
    "df_h11_h6_2 = dict(N=len(fish),\n",
    "                  log_hours = fish['log_hours'],\n",
    "                  fish = fish['fish_caught'],\n",
    "                  child = fish['child'],\n",
    "                  persons = fish['persons'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_c32a3ce4c02e39ec64c11fedc2fb2436.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "ap     0.76    0.01   0.55   -0.3   0.39   0.76   1.13   1.82   1839    1.0\n",
       "al     -2.3  3.5e-3   0.15   -2.6  -2.41   -2.3   -2.2  -2.02   1837    1.0\n",
       "bp0   -1.01  6.3e-3   0.27  -1.56  -1.18   -1.0  -0.83  -0.52   1820    1.0\n",
       "bc0    1.01    0.01   0.56  -0.26   0.68   1.05   1.38   1.95   2558    1.0\n",
       "bp     0.67  9.9e-4   0.04   0.59   0.65   0.67    0.7   0.76   1794    1.0\n",
       "bc     0.56  1.8e-3   0.09   0.37    0.5   0.56   0.62   0.74   2720    1.0\n",
       "lp__  -1050    0.05   1.82  -1054  -1051  -1050  -1049  -1047   1406    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Mon May 25 23:40:44 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_h11_h6_2 = sm_11_h6_2.sampling(data=df_h11_h6_2)\n",
    "\n",
    "fit_h11_h6_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
